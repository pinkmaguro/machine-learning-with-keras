{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN (recurrent neural network), 순환 신경망 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n",
    "from keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 설명\n",
    "\n",
    "영화평(리뷰)와 긍정리뷰또는 부정리뷰의 레이블 정보가 있는 데이터셋\n",
    "\n",
    "파일로 다운로드를 받으면 영어로된 원본 영화평을 볼 수 있습니다.\n",
    "\n",
    "\n",
    "http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "긍정리뷰의 예\n",
    "\n",
    "ONE DARK NIGHT is a highly overlooked and little known film from the early 80's that deserves an audience that I fear it will never get, and that's a damn shame. I have seen this film compared to others that have gotten a bigger name over the years, most notably PHANTASM, HELL NIGHT and MAUSOLEUM. This is a much different film than those and I don't see the comparisons other than the mausoleum, which is a bit similar to the one in PHANTASM, but not enough to make any real comparisons. ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=20000\n",
    "maxlen=80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 딴어의 빈도수가 max_features 등 안에 드는 단어만 취급\n",
    "- maxlen : 한 문장의 최대 단어수\n",
    "- 그외의 옵션은 케라스 홈페이지에서 확인할 수 있습니다.\n",
    "\n",
    "https://keras.io/datasets/\n",
    "\n",
    "path: if you do not have the data locally (at '~/.keras/datasets/' + path), it will be downloaded to this location.\n",
    "num_words: integer or None. Top most frequent words to consider. Any less frequent word will appear as oov_char value in the sequence data.\n",
    "skip_top: integer. Top most frequent words to ignore (they will appear as oov_char value in the sequence data).\n",
    "maxlen: int. Maximum sequence length. Any longer sequence will be truncated.\n",
    "seed: int. Seed for reproducible data shuffling.\n",
    "start_char: int. The start of a sequence will be marked with this character. Set to 1 because 0 is usually the padding character.\n",
    "oov_char: int. words that were cut out because of the num_words or skip_top limit will be replaced with this character.\n",
    "index_from: int. Index actual words with this index and higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_Y), (test_X, test_Y) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, list)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_X), type(train_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(train_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19972"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.max(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 80)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x = sequence.pad_sequences(train_X, maxlen=maxlen)\n",
    "tmp_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_imdb_data(max_features=20000, maxlen=80):\n",
    "    (train_X, train_Y), (test_X, test_Y) = imdb.load_data(num_words=max_features,\n",
    "                                                         )\n",
    "    train_X = sequence.pad_sequences(train_X, maxlen=maxlen)\n",
    "    test_X = sequence.pad_sequences(test_X, maxlen=maxlen)\n",
    "    return (train_X, train_Y), (test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 80)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_X, train_Y), (test_X, test_Y) = prepare_imdb_data()\n",
    "\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(models.Model):\n",
    "    def __init__(self, max_features, maxlen):\n",
    "        x = layers.Input((maxlen,))\n",
    "        print(x)\n",
    "        h = layers.Embedding(max_features, 128)(x)\n",
    "        print(h)\n",
    "        h = layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2)(h)\n",
    "        print(h)\n",
    "        y = layers.Dense(1, activation='sigmoid')(h)\n",
    "        print(y)\n",
    "        super().__init__(x, y)\n",
    "        \n",
    "        self.compile(loss='binary_crossentropy',\n",
    "                        optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        \n",
    "class LSTMMachine:\n",
    "    def __init__(self, max_features=20000, maxlen=80):\n",
    "        self.data = prepare_imdb_data(max_features, maxlen)\n",
    "        print(self.data)\n",
    "        self.model = LSTM(max_features, maxlen)\n",
    "        \n",
    "    def run(self, epochs=3, batch_size=32):\n",
    "        data = self.data\n",
    "        (train_X, train_Y), (test_X, test_Y) = data\n",
    "        model = self.model\n",
    "        model.fit(train_X, train_Y, batch_size=batch_size, epochs=epochs,\n",
    "                         validation_data=(test_X, test_Y))\n",
    "        score, acc = model.evaluate(test_X, test_Y, batch_size=batch_size)\n",
    "        print('Test performance: accuracy={}, loss={}'.format(acc, score))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((array([[   15,   256,     4, ...,    19,   178,    32],\n",
      "       [  125,    68,     2, ...,    16,   145,    95],\n",
      "       [  645,   662,     8, ...,     7,   129,   113],\n",
      "       ..., \n",
      "       [  529,   443, 17793, ...,     4,  3586,     2],\n",
      "       [  286,  1814,    23, ...,    12,     9,    23],\n",
      "       [   97,    90,    35, ...,   204,   131,     9]], dtype=int32), array([1, 0, 0, ..., 0, 1, 0])), (array([[   0,    0,    0, ...,   14,    6,  717],\n",
      "       [1669,  398,  229, ...,  125,    4, 3077],\n",
      "       [ 687,    2,  203, ...,    9,   57,  975],\n",
      "       ..., \n",
      "       [   0,    0,    0, ...,   21,  846, 5518],\n",
      "       [   8,   97,   14, ..., 2302,    7,  470],\n",
      "       [ 718,    2,    9, ...,   34, 2005, 2643]], dtype=int32), array([0, 1, 1, ..., 0, 0, 0])))\n",
      "Tensor(\"input_1:0\", shape=(?, 80), dtype=float32)\n",
      "Tensor(\"embedding_1/Gather:0\", shape=(?, 80, 128), dtype=float32)\n",
      "Tensor(\"lstm_1/TensorArrayReadV3:0\", shape=(?, 128), dtype=float32)\n",
      "Tensor(\"dense_1/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 432s 17ms/step - loss: 0.4621 - acc: 0.7765 - val_loss: 0.3968 - val_acc: 0.8277\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 417s 17ms/step - loss: 0.3007 - acc: 0.8783 - val_loss: 0.3751 - val_acc: 0.8351\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 513s 21ms/step - loss: 0.2148 - acc: 0.9168 - val_loss: 0.4004 - val_acc: 0.8280\n",
      "25000/25000 [==============================] - 83s 3ms/step\n",
      "Test performance: accuracy=0.82796, loss=0.4003766143989563\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    machine = LSTMMachine()\n",
    "    machine.run()\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
